{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b23bf8d9-66aa-4750-8b93-6f2675d43bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import geojson\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import pandas as pd\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bfa2bb-57a7-41a0-8157-af31b1bd3701",
   "metadata": {},
   "source": [
    "# Download some data\n",
    "First we need to get some data. In this example we are interested in the production of salmon and trout in Norway. The Norwegian Fisheries Directorate provides this data in the form of xlsx files. But when we bring that into our environment, it needs some work to clean it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f95ae851-b36c-4310-87c5-78ffcd1839c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.fiskeridir.no/English/Aquaculture/Statistics/Atlantic-salmon-and-rainbow-trout/grow-out-production/sta-laks-mat-11-beh-bevegelse.xlsx\"\n",
    "\n",
    "# Read all sheets into a dictionary of DataFrames\n",
    "xlsx_data = pd.read_excel(url, sheet_name=None)\n",
    "\n",
    "# Concatenate all DataFrames into one with a new 'Year' column\n",
    "combined_dfs = []\n",
    "for year, df in xlsx_data.items():\n",
    "    df['Year'] = year  # Add a new column with the year\n",
    "    combined_dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "combined_df = pd.concat(combined_dfs, ignore_index=True)\n",
    "\n",
    "# Print or further process the combined DataFrame\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518ecbb5-f773-4055-8efd-f044cd05509f",
   "metadata": {},
   "source": [
    "# Transforming up the data\n",
    "In the next few cells, we are going to be transforming the dataset into something that is easier to work with. By the end of this process, we will have a nice table with the production data by year for both trout and salmon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73d84f48-4ab2-45f9-848d-4ba1e7fe95cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already executed the code to create the 'combined_df' DataFrame\n",
    "display(combined_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c9837ec-14c2-4a8c-854c-fdd1663a2688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the data\n",
    "# Specify the desired terms\n",
    "desired_terms = [\n",
    "    \"Troms og Finnmark\",\n",
    "    \"Nordland\",\n",
    "    \"Trøndelag\",\n",
    "    \"Møre og Romsdal\",\n",
    "    \"Vestland\",\n",
    "    \"Rogaland\",\n",
    "    \"Øvrige fylker\"\n",
    "]\n",
    "\n",
    "# Filter the DataFrame based on the first column\n",
    "filtered_df = combined_df[combined_df.iloc[:, 0].isin(desired_terms)]\n",
    "\n",
    "# Duplicate the rows\n",
    "filtered_df = pd.concat([filtered_df] * 2, ignore_index=True)\n",
    "\n",
    "# Add a new column labeling rows with \"Rainbow Trout\" or \"Atlantic Salmon\"\n",
    "filtered_df['Label'] = ['Rainbow Trout'] * (len(filtered_df) // 2) + ['Atlantic Salmon'] * (len(filtered_df) // 2)\n",
    "\n",
    "# Display the modified DataFrame\n",
    "display(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eb3e98a-0bbe-4d65-b37b-22d287b66352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping for column renaming\n",
    "column_mapping = {\n",
    "    'Laks, regnbueørret og ørret - matfiskproduksjon': 'County',\n",
    "    'Unnamed: 1': 'Live stock pr. 1.1',\n",
    "    'Unnamed: 2': 'Input',\n",
    "    'Unnamed: 3': 'Output',\n",
    "    'Unnamed: 4': 'Losses',\n",
    "    'Unnamed: 5': 'Live stock pr. 12.31.',\n",
    "    'Label': 'Species'\n",
    "}\n",
    "\n",
    "# Rename columns in the DataFrame\n",
    "filtered_df.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "# Display the DataFrame with the new column names\n",
    "display(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43beaee4-fe88-494a-ac31-b2131955cd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(filtered_df)\n",
    "\n",
    "# Set hierarchical index with 'County', 'Year', and 'Species'\n",
    "df.set_index(['County', 'Year', 'Species'], inplace=True)\n",
    "\n",
    "# Sort the index for better readability\n",
    "df.sort_index(axis=0, level=['County', 'Year', 'Species'], inplace=True)\n",
    "\n",
    "# Reset the index to make 'County', 'Year', and 'Species' regular columns\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# Display the modified DataFrame\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce8faaed-eae7-48a3-a566-87b096e29f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate the rows with the first three columns\n",
    "filtered_df = pd.concat([df.iloc[:, :3]] * 2, ignore_index=True)\n",
    "\n",
    "# Add the last five columns' values under columns 4 to 8\n",
    "filtered_df[df.columns[3:8]] = df.iloc[:, 3:].values.reshape(-1, 5)\n",
    "\n",
    "# Display the modified DataFrame\n",
    "display(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff293b9e-f51f-4b79-b754-7a1e7e7d85fc",
   "metadata": {},
   "source": [
    "# Exporting as csv\n",
    "Now we have a nice looking table, we can export it as a csv file or take it one step further and upload it to our own data collection in ODP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef15c30f-e94a-4e25-b1cb-809d8f442478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pandas to csv\n",
    "csv_filename = \"atlantic-salmon-rainbow-trout-and-trout-grow-out-production.csv\"\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "filtered_df.to_csv(csv_filename, index=False)\n",
    "\n",
    "# Display a message indicating successful save\n",
    "print(f\"DataFrame has been saved to {csv_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e79a1b0-f735-4ecb-b79c-3d32b8c1265c",
   "metadata": {},
   "source": [
    "# Uploading Data to ODP\n",
    "In the next step, we are going to be doing a few things that will allow us to upload our data to ODP.\n",
    "1. Creating a data collection\n",
    "2. Creating a dataset inside collection\n",
    "3. Definin a schema for our data\n",
    "4. Uploading the data to ODP\n",
    "\n",
    "We are going to be following the quickstart guide to help us: https://docs.hubocean.earth/guides/quickstart/\n",
    "    \n",
    "But first we need our token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d96c8018-6e64-4fff-be34-226f7e490f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = requests.post(\"http://localhost:8000/access_token\").json()['token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f532281-b4cc-4e30-92a2-d851b265867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7324d4ab-fb81-4c7b-8a41-057b6121838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {token}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"X-ODP-CHUNKED-ENCODING\": \"false\"\n",
    "}\n",
    "base_url = \"https://api.hubocean.earth\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193d584f-4788-49e8-8fd9-7249c6342a62",
   "metadata": {},
   "source": [
    "## Creating a Data Collection\n",
    "First we need to create our data collection. In the first cell we name both the collection and the dataset. These names need to be computer friendly, but we can make nicer ones later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9b67171-2751-4ccd-bd26-fcf8bef01a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_collection_name = \"norwegian-directorat-of-fisheries-grow-out-production\" # Use the existing name or make-your-own-computer-friendly-name\n",
    "dataset_name = \"overview-of-the-live-stock-1998-2022\" # Use the existing name or make-your-own-computer-friendly-name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4f93f45-20a4-4b2d-b198-82151b735c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data collection\n",
    "\n",
    "endpoint = f\"/catalog\"\n",
    "url = base_url + endpoint\n",
    "\n",
    "body = {\n",
    "    \"kind\": \"catalog.hubocean.io/dataCollection\",\n",
    "    \"version\": \"v1alpha1\",\n",
    "    \"metadata\": {\n",
    "        \"name\": f\"{dataset_collection_name}\",\n",
    "        \"display_name\": \"Norwegian Directorat of Fisheries- Grow Out Production\",\n",
    "        \"description\": \"Overview of the livestock 1998-2022\",\n",
    "        \"labels\": {\n",
    "            \"hubocean.io/test\": 'true'\n",
    "        }\n",
    "    },\n",
    "    \"spec\": {\n",
    "        \"distribution\": {\n",
    "            \"published_by\": {\n",
    "                \"contact\": \"Tom Redd <mail@address.earth>\",\n",
    "                \"organisation\": \"HUB Ocean\"\n",
    "            },\n",
    "            \"published_date\": \"2019-06-19T06:00:00\",\n",
    "            \"website\": \"https://hubocean.earth\",\n",
    "            \"license\": {\n",
    "                \"name\": \"propriatary\",\n",
    "                \"full_text\": \"This is a very strict legal text describing the data license for this data collection. The lawyer would be proud.\",\n",
    "                \"href\": \"www.license.com\"\n",
    "            }\n",
    "        },\n",
    "        \"tags\": [\"test\", \"hubocean\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=body, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    json_response = response.json()\n",
    "else:\n",
    "       print(f\"Request failed with status code {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "054eb73b-5ece-4063-929d-c153dc45ad56",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check to see if the data collection exists\n",
    "\n",
    "resource_group = \"catalog.hubocean.io\"\n",
    "resource_type = \"dataCollection\"\n",
    "endpoint = f\"/catalog/{resource_group}/{resource_type}/{dataset_collection_name}\"\n",
    "url = base_url + endpoint\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    json_response = response.json()\n",
    "else:\n",
    "   print(f\"Request failed with status code {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3bca625-a7ab-45e8-bbf2-3cb6ea31d0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b01ad6d-847e-4587-b5f8-f2516148fc99",
   "metadata": {},
   "source": [
    "## Creating a Dataset\n",
    "Now we have a data collection we can make one or multiple datasets inside it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc00c95b-48d9-4712-bcd8-85caf26891ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset inside collection\n",
    "\n",
    "endpoint = \"/catalog\"\n",
    "url = base_url + endpoint\n",
    "\n",
    "body = {\n",
    "    \"kind\": \"catalog.hubocean.io/dataset\",\n",
    "    \"version\": \"v1alpha3\",\n",
    "    \"metadata\": {\n",
    "        \"name\": f\"{dataset_name}\",\n",
    "        \"display_name\": \"Atlantic salmon, Rainbow trout and Trout - Grow out production\",\n",
    "        \"description\": \"Official statistics\",\n",
    "        \"labels\": {\n",
    "            \"hubocean.io/test\": \"true\"\n",
    "        }\n",
    "    },\n",
    "    \"spec\": {\n",
    "        \"data_collection\": f\"catalog.hubocean.io/dataCollection/{dataset_collection_name}\",\n",
    "        \"storage_class\": \"registry.hubocean.io/storageClass/tabular\",\n",
    "        \"storage_controller\": \"registry.hubocean.io/storageController/storage-tabular\",\n",
    "        \"maintainer\": {\n",
    "            \"contact\": \"Redd, Tom <tom.redd@oceandata.earth>\",\n",
    "            \"organisation\": \"HUB Ocean\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=body, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    json_response = response.json()\n",
    "    print(json_response)\n",
    "\n",
    "else:\n",
    "    print(f\"Request failed with status code {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b924c7ba-3d8b-4282-ba16-398e65a34e40",
   "metadata": {},
   "source": [
    "## Creating a Schema\n",
    "Before we upload the data, we need to make a schema describing the data. If you look above you will see that the schema coresponds to the column headings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a707d68-a491-457d-b00e-6eca3785d988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table schema\n",
    "\n",
    "kind = \"catalog.hubocean.io/dataset\"\n",
    "\n",
    "endpoint = f\"/data/{kind}/{dataset_name}/schema\"\n",
    "body = {\n",
    "    \"table_schema\": {\n",
    "        \"County\": {\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        \"Year\": {\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        \"Species\": {\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        \"Live stock pr. 1.1\": {\n",
    "            \"type\": \"double\"\n",
    "        },\n",
    "        \"Input\": {\n",
    "            \"type\": \"double\"\n",
    "        },\n",
    "        \"Output\": {\n",
    "            \"type\": \"double\"\n",
    "        },\n",
    "        \"Losses\": {\n",
    "            \"type\": \"double\"\n",
    "        },\n",
    "        \"Live stock pr. 12.31.\": {\n",
    "            \"type\": \"double\"\n",
    "        },\n",
    "    },\n",
    "    \"table_description\": \"Overview over the live stock by county. The number of units in 1000\",\n",
    "    \"geospatial_partition_columns\": [\n",
    "        \"Location\"\n",
    "    ],\n",
    "    \"geospatial_partition_hash_precision\": 5,\n",
    "    \"table_metadata\": {\n",
    "        \"geometry\": {\n",
    "            \"primary_location\": \"Location\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "url = base_url + endpoint\n",
    "response = requests.post(url, json=body, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    json_response = response.json()\n",
    "    print(json_response)\n",
    "\n",
    "else:\n",
    "    print(f\"Request failed with status code {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a118c130-9fe7-48d0-a628-b06a2e12a714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Schema by dataset name\n",
    "\n",
    "kind = \"catalog.hubocean.io/dataset\"\n",
    "\n",
    "endpoint = f\"/data/{kind}/{dataset_name}/schema\"\n",
    "\n",
    "url = base_url + endpoint\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    json_response = response.json()\n",
    "    print(json_response)\n",
    "\n",
    "else:\n",
    "    print(f\"Request failed with status code {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cd7118-a3e5-45d3-b8b8-b3bd4f8f474b",
   "metadata": {},
   "source": [
    "## Uploading Data to ODP\n",
    "Now we actually get to upload the data from the table we created. We are using a simple function to automate this process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83609a84-0a3f-4084-b16b-c18d510cede0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datapoints for all rows in the DataFrame\n",
    "datapoints = []\n",
    "\n",
    "for index, row in filtered_df.iterrows():\n",
    "    datapoint = {\n",
    "        \"County\": row['County'],\n",
    "        \"Year\": row['Year'],\n",
    "        \"Species\": row['Species'],\n",
    "        \"Live stock pr. 1.1\": row['Live stock pr. 1.1'],\n",
    "        \"Input\": row['Input'],\n",
    "        \"Output\": row['Output'],\n",
    "        \"Losses\": row['Losses'],\n",
    "        \"Live stock pr. 12.31.\": row['Live stock pr. 12.31.'],\n",
    "    }\n",
    "    datapoints.append(datapoint)\n",
    "\n",
    "# Create the body for the request\n",
    "body = {\"data\": datapoints}\n",
    "print(datapoints[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8b292e6-76ac-4d84-b098-86cb858cba01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "kind = \"catalog.hubocean.io/dataset\"\n",
    "\n",
    "endpoint = f\"/data/{kind}/{dataset_name}\"\n",
    "\n",
    "url = base_url + endpoint\n",
    "\n",
    "response = requests.post(url, json=body, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    json_response = response.json()\n",
    "    print(json_response)\n",
    "else:\n",
    "    print(f\"Request failed with status code {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8703bc-53b3-47c6-a5ed-a1bb85c7c743",
   "metadata": {},
   "source": [
    "## Not sure what we are doing here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "094d5c85-b16a-4ec7-aaf3-b183b53f18e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query for our dataset with the OQS syntax.\n",
    "\n",
    "endpoint = \"/catalog/list\"\n",
    "body = {\n",
    "    \"oqs\": {\n",
    "        \"#EQUALS\": [\n",
    "            \"$metadata.name\",\n",
    "            \"overview-of-the-live-stock-1998-2022\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "url = base_url + endpoint\n",
    "response = requests.post(url, json=body, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    json_response = response.json()\n",
    "    print(json_response)\n",
    "\n",
    "else:\n",
    "    print(f\"Request failed with status code {response.status_code} - {response.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773645dc-6731-4c6c-aaf0-57c55bdafdc9",
   "metadata": {},
   "source": [
    "# Pulling Data from the ODP API\n",
    "Now the data is stored in ODP, we can test to see if its working and start to think about how we might analyse it. To make things a bit more managable, you might want to filter the data by county and year so lets make a something to help with that. We then use this input to filter the data we pull from the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b84e067a-edfa-4b44-9129-778e3d674fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of counties\n",
    "county_list = [\n",
    "    'Troms og Finnmark',\n",
    "    'Nordland',\n",
    "    'Trøndelag',\n",
    "    'Møre og Romsdal',\n",
    "    'Vestland',\n",
    "    'Rogaland',\n",
    "    'Øvrige fylker'\n",
    "]\n",
    "\n",
    "# Define a dropdown widget for selecting the county\n",
    "county_dropdown = widgets.Dropdown(\n",
    "    options=county_list,\n",
    "    value=county_list[0],  # Set the default selected county\n",
    "    description='Select County:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "# Create a slider widget\n",
    "year_slider = widgets.IntSlider(\n",
    "    value=2022,  # Initial value\n",
    "    min=1998,    # Minimum year\n",
    "    max=2030,    # Maximum year\n",
    "    step=1,      # Step size\n",
    "    description='Select Year:',\n",
    "    continuous_update=False  # Set to False to update only on slider release\n",
    ")\n",
    "\n",
    "# Display the slider\n",
    "display(year_slider)\n",
    "\n",
    "# Display the dropdown widget\n",
    "display(county_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6d2ee4d-e662-4ed5-b4f2-40b5f7eecefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_county = county_dropdown.value\n",
    "selected_year = year_slider.value\n",
    "print(selected_county)\n",
    "print(selected_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "372782a3-f55d-42be-99f5-0dd6f4443333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query for our dataset with the OQS syntax.\n",
    "\n",
    "resource_group = \"catalog.hubocean.io\"\n",
    "resource_type = \"dataset\"\n",
    "\n",
    "endpoint = f\"/data/{resource_group}/{resource_type}/{dataset_name}/list\"\n",
    "\n",
    "\n",
    "body = {\n",
    "    \"filters\": {\n",
    "        \"#AND\": [\n",
    "            {\n",
    "                \"#EQUALS\": [\"$County\", selected_county]\n",
    "            },\n",
    "            {\n",
    "                \"#EQUALS\": [\"$Year\", selected_year]\n",
    "            }\n",
    "            # Add more filters if needed\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "url = base_url + endpoint\n",
    "response = requests.post(url, json=body, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(response.json())\n",
    "\n",
    "else:\n",
    "    print(f\"Request failed with status code {response.status_code} - {response.text}\")\n",
    "    \n",
    "pd.json_normalize(data_json_response['data'], max_level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80961e99-692c-4b23-90d4-2c1c4d435daa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118e24a7-c808-4242-af89-ef6a8d726dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
